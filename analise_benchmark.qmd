---
title: "analise_benchmark"
format: html
editor: visual
---

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import polars as pl
```

```{r}
library(JuliaCall)

# Instalar o pacote PrettyTables dentro do ambiente Julia
julia_eval('import Pkg; Pkg.add("PrettyTables")')
```

```{julia}
using CSV, DataFrames, Statistics, PrettyTables
#using Plots 

```

## 1. Integrantes do Grupo

Diego Pires Silva, Henry Koiti Honda e Joaquim Bertoldi Nucci

### 2. Motivação e introdução

Todo cientista de dados conhece a dor: você dá o "play" no código para carregar um arquivo e fica esperando minutos,às vezes horas, olhando para a tela enquanto a memória RAM do computador vai para o limite.

O problema é claro: os dados estão cada vez maiores, mas nossos notebooks continuam, na média, com os mesmos 16GB de RAM. Ferramentas clássicas que aprendemos na faculdade, como o Pandas ou o comando básico do R, foram criadas anos atrás e muitas vezes vão penar quando o arquivo é grande demais.

Hoje, fala-se muito que o **Polars** e o formato **Parquet** são a solução mágica para isso. Mas será que são mesmo?

A motivação deste estudo é simples: colocar essas ferramentas à prova na prática. Quero descobrir se vale a pena gastar tempo aprendendo uma nova biblioteca para ganhar velocidade, e se é possível trabalhar com grandes volumes de dados no meu próprio notebook, sem precisar de computadores da NASA ou pagar caro por nuvem.

### 3. Metodologia Experimental

O experimento foi estruturado para avaliar o desempenho das bibliotecas em um cenário de restrição de recursos, representativo de uma estação de trabalho local (notebook da maioria dos aspirantes à estatísticos ou cientistas de dados como nós!) , isolando variáveis de hardware e software que poderiam introduzir ruído nas medições.

**3.1. Infraestrutura:** Os experimentos foram conduzidos em um notebook MSI Cyborg 14, operando sobre Windows 11 nativo. Para evitar a variabilidade introduzida pelo escalonamento de frequência da CPU e gerenciamento de energia, o equipamento foi mantido conectado à fonte de alimentação ininterrupta (no carregador), com o perfil de energia do sistema operacional fixado em "Alta Performance". Durante as baterias de testes, processos concorrentes foram encerrados, mantendo-se ativos estritamente o ambiente de execução (R/Python) e o diretório de dados, visando minimizar a interferência no consumo de qualquer outra coisa que estivesse aberta no computador. e

As especificações de hardware incluem um processador Intel Core i7, GPU NVIDIA RTX 4050 e 16GB de memória RAM. Este último componente define o teto físico de operação para as bibliotecas *in-memory*, servindo como principal variável de estresse nos testes de volume.

**3.2. Dados e Fontes** A seleção dos datasets buscou cobrir três vetores distintos de complexidade computacional:

-   **Volume e Extensão (Giga & Long):** Utilizou-se os dados históricos de viagens de táxi de Nova Iorque (*NYC Taxi & Limousine Commission - TLC Trip Record Data*). O dataset "Giga" avalia a capacidade de vazão (*throughput*) e gerenciamento de memória próxima à saturação, enquanto o recorte "Long" foca na eficiência de processamento vetorial em milhões de linhas. São referências em benchmarks desse tipo.

-   **Dimensionalidade (Wide):** Para avaliar o *overhead* de processamento de colunas e inferência de tipos heterogêneos, utilizou-se o *Stack Overflow Annual Developer Survey*, caracterizado por sua estrutura larga e mix de dados numéricos e textuais.

**3.3. Versionamento e tecnologias:** A reprodutibilidade dos resultados fundamenta-se nas versões específicas das bibliotecas, dado que implementações recentes (como por exemplo, o backend PyArrow no Pandas 2.0) alteram significativamente a performance de leitura.

-   **Ambiente Python (3.13):** Polars 1.33.1, Pandas 2.2.2, PyArrow 19.0.0 e NumPy 2.2.2.

-   **Ambiente R (4.4.3):** readr 2.1.5, arrow 21.0.0.1, dplyr 1.1.4 e glue 1.8.0.

-   **Ambiente Julia (1.2.0)**

**3.4. Protocolo de Medição** Cada cenário experimental, definido pela Biblioteca, Formato e tipo de dataset, foi submetido a 10 execuções consecutivas. A métrica de avaliação adotada foi a mediana dos tempos de execução, estratégia utilizada para neutralizar *outliers* decorrentes de latências momentâneas do sistema operacional ou do disco. Os logs de consumo de memória foram capturados em intervalos de milissegundos para identificar picos de uso e o comportamento de *Garbage Collection*.

Foram realizadas 338 amostras de importação desses conjuntos de dados separados em A1, A2 e A3 em que A1 é a imporação comum que foi importado com todas as bibliotecas, csv e parquet. A2 importação definindo um schema prévio que foi realizadas apenas em CSV para o Dataset Yellowlong para todas as bibliotecas. E A3 que é a análise dos conjuntos de dados "removendo" algumas colunas na leitura que foi realizada da mesma forma que o A2.

```{python}
pd.set_option('display.max_columns', None)
sns.set_theme(style="whitegrid", context="talk")
plt.rcParams['figure.figsize'] = (12, 6)
```

```{python}
df_master = pd.read_csv("MASTER_BENCHMARK_DATA.csv")
```

```{python}
# Filtro: Vamos olhar apenas para o Cenário 1 (Leitura Pura) para ser justo
# Agrupamento pelas variáveis categóricas
tabela_descritiva = df_master.groupby(['Dataset', 'Cenario', 'Formato', 'Biblioteca']).agg(
    Tempo_Medio_s=('Tempo_Segundos', 'mean'),
    Tempo_Min_s=('Tempo_Segundos', 'min'),
    Tempo_Std=('Tempo_Segundos', 'std'),  # Indica instabilidade
    RAM_Pico_GB=('RAM_Pico_GB', 'max'),   # O pior caso de RAM é o que importa para evitar OOM
    Amostras=('Iteracao', 'count')
).reset_index()

# Cálculo do Coeficiente de Variação (CV%) - para medir estabilidade percentual
# CV < 5% = Muito estável | CV > 20% = Instável
tabela_descritiva['Estabilidade_CV_Pct'] = (
    tabela_descritiva['Tempo_Std'] / tabela_descritiva['Tempo_Medio_s']
) * 100

# Ordenar para facilitar leitura
tabela_descritiva = tabela_descritiva.sort_values(by=['Dataset', 'Cenario', 'Tempo_Medio_s'])

# Exibir tabela formatada
print("--- Tabela Descritiva Geral ---")
print(tabela_descritiva)
```

# 4.1 Comparação entre performance A1

```{python}
# Correção: Usando 'Tempo_Segundos' (coluna original) e calculando a média na hora
df_41 = df_master[df_master['Cenario'] == '1_Leitura_Pura'].copy()

# Pivotagem
tabela_formatos = df_41.pivot_table(
    index=['Dataset', 'Biblioteca'], 
    columns='Formato', 
    values='Tempo_Segundos',  # <--- Nome corrigido aqui
    aggfunc='mean'            # <--- O Python calcula a média aqui
).reset_index()

# Cálculo do Speedup (Aceleração)
# Garante que as colunas existam antes de calcular (caso falte algum dado)
if 'CSV' in tabela_formatos.columns and 'Parquet' in tabela_formatos.columns:
    tabela_formatos['Speedup_X'] = tabela_formatos['CSV'] / tabela_formatos['Parquet']
else:
    print("AVISO: Faltam dados de CSV ou Parquet para calcular o Speedup.")

# Limpeza e Exibição
tabela_output = tabela_formatos.dropna(subset=['Speedup_X']).sort_values(
    by=['Dataset', 'Speedup_X'], 
    ascending=[True, False]
)

cols = ['Dataset', 'Biblioteca', 'CSV', 'Parquet', 'Speedup_X']
print("--- Tabela para Análise 4.1 ---")
# O to_string garante que o Pandas não corte as linhas no terminal
print(tabela_output[cols].round(2).to_string(index=False))
```

-   **1. A Vitória da Julia no Parquet (Giga)** A grande surpresa do teste Giga foi a performance da Julia no formato Parquet. Com um tempo de **8.23 segundos**, a Julia foi a **campeã absoluta de leitura binária**, superando o Polars (9.41s) e o Pandas (12.16s). Isso comprova que a arquitetura da linguagem é extremamente eficiente para I/O de dados estruturados, justificando sua fama em computação de alta performance.

    **2. A Hegemonia do Polars no CSV** No formato CSV, o cenário se inverte. Enquanto Julia e Pandas levaram cerca de **3 minutos** (177s e 201s) para ler o arquivo gigante, o Polars terminou a tarefa em **51 segundos**.

    -   **Diagnóstico:** O leitor de CSV da Julia (`CSV.jl`), embora ligeiramente mais rápido que o Pandas, ainda sofre do mesmo gargalo: o custo de converter texto para número. O Polars vence aqui por sua engine especializada em *multithreading* agressivo para texto.

    **3. O Maior Ganho de Migração (Speedup)** A Julia apresentou o maior benefício ao trocar de formato: um ganho de **21.5x** no Giga e **28x** no dataset Longo.

    -   **Interpretação:** Para usuários de Julia (e R), abandonar o CSV não é opcional, é uma questão de sobrevivência. A diferença entre esperar 3 minutos (CSV) e esperar 8 segundos (Parquet) altera completamente a fluidez do trabalho. No Polars, o ganho é "menor" (5x) apenas porque ele já era excepcionalmente rápido no CSV.

    **4. A Instabilidade no "Wide"** Vale notar que no dataset *StackOverflow* (muitas colunas), a Julia teve um desempenho inferior (3.65s no CSV), perdendo para R Base e Pandas. Isso sugere que a compilação JIT (tempo de inicialização da Julia) ou o overhead de gerenciar muitas colunas textuais tem um peso maior em arquivos menores, onde a "força bruta" da linguagem não tem tempo de brilhar.

```{python}
# Preparação dos dados para 4.2 - Foco no Dataset Giga (Estresse)
# Agrupando por Biblioteca e Formato para pegar a Mediana do Tempo e o Máximo de RAM
df_giga_agg = df_master[
    (df_master['Dataset'] == 'Giga_Yellow') & 
    (df_master['Cenario'] == '1_Leitura_Pura')
].groupby(['Formato', 'Biblioteca']).agg(
    Tempo_Mediano_s=('Tempo_Segundos', 'median'),
    RAM_Pico_GB=('RAM_Pico_GB', 'max')
).reset_index()

# Tabela A: Ranking CSV
ranking_csv = df_giga_agg[df_giga_agg['Formato'] == 'CSV'].sort_values('Tempo_Mediano_s')
# Adiciona coluna de comparação (Quantas vezes mais lento que o 1º lugar)
melhor_tempo_csv = ranking_csv['Tempo_Mediano_s'].iloc[0]
ranking_csv['X_Vezes_Mais_Lento'] = ranking_csv['Tempo_Mediano_s'] / melhor_tempo_csv

# Tabela B: Ranking Parquet
ranking_parquet = df_giga_agg[df_giga_agg['Formato'] == 'Parquet'].sort_values('Tempo_Mediano_s')
melhor_tempo_parquet = ranking_parquet['Tempo_Mediano_s'].iloc[0]
ranking_parquet['X_Vezes_Mais_Lento'] = ranking_parquet['Tempo_Mediano_s'] / melhor_tempo_parquet

print("--- Ranking Giga CSV (Processamento Puro) ---")
print(ranking_csv[['Biblioteca', 'Tempo_Mediano_s', 'RAM_Pico_GB', 'X_Vezes_Mais_Lento']].round(2).to_string(index=False))

print("\n--- Ranking Giga Parquet (IO Puro) ---")
print(ranking_parquet[['Biblioteca', 'Tempo_Mediano_s', 'RAM_Pico_GB', 'X_Vezes_Mais_Lento']].round(2).to_string(index=False))
```

```{python}
# Preparação dos dados para 4.3 - Eficiência de Memória
# Vamos comparar o comportamento em CSV, onde a gestão de memória é mais crítica

df_memoria = df_master[
    (df_master['Cenario'] == '1_Leitura_Pura') & 
    (df_master['Formato'] == 'CSV') &
    (df_master['Dataset'].isin(['Yellow_Long', 'Giga_Yellow']))
].groupby(['Dataset', 'Biblioteca']).agg(
    RAM_Pico_GB=('RAM_Pico_GB', 'max'),
    Tempo_Mediano_s=('Tempo_Segundos', 'median')
).reset_index()

# Pivotar para comparar os Datasets lado a lado
tabela_memoria = df_memoria.pivot_table(
    index='Biblioteca', 
    columns='Dataset', 
    values='RAM_Pico_GB'
).reset_index()

# Calcular o "Overhead" (Se possível, mas vamos focar nos valores absolutos)
print("--- Pico de Uso de Memória (GB) - CSV ---")
print(tabela_memoria.round(2).to_string(index=False))
```

### 4.3. Eficiência de Memória e Limites de Hardware

A tabela do consumo de memória RAM revela o limite físico da infraestrutura de teste e a eficiência de gerenciamento de cada biblioteca. A tabela abaixo compara o pico de memória exigido para carregar os datasets em formato CSV.

#### Análise: O Muro dos 16GB

**1. Diagnóstico de Saturação (Dataset Giga)** No cenário de estresse, **todas** as bibliotecas atingiram o teto de **15.71 GB**. Isso comprova que o hardware foi o fator limitante.

-   **Consequência:** O esgotamento da RAM física forçou o sistema operacional a usar *Swap* (disco como memória), degradando drasticamente a performance de Pandas, R e Julia (tempos \> 170s).

-   **A Exceção:** O Polars, mesmo saturando a memória, conseguiu finalizar a tarefa em 51s. Sua arquitetura *Lazy* gerenciou o *Swap* de forma muito mais eficiente que os concorrentes.

**2. O Custo da Velocidade (Dataset Long)** No cenário onde a memória *não* acabou, o comportamento natural das engines se revelou:

-   **R Base e Julia (Eficiência):** Foram os mais econômicos (\~9GB e \~10GB). A Julia demonstrou um gerenciamento de memória superior ao Pandas, consumindo 20% menos RAM para a mesma tarefa.

-   **Polars (Consumo Agressivo):** Foi o que mais consumiu memória (14.5 GB). Isso confirma que o Polars troca espaço por velocidade: ele aloca grandes *buffers* para alimentar seus núcleos paralelos.

> **Insight Prático:** Velocidade custa memória. Se você tem pouca RAM disponível (ex: containers Docker pequenos de 4GB), o **R Base** ou **Julia** são escolhas mais seguras contra travamentos (*crashes*). O **Polars** deve ser usado quando há memória sobrando para "queimar" em troca de performance máxim

#### 4.4. Otimização Manual: Esforço vs. Recompensa

Além da escolha da ferramenta, nós (como bons alunos de ME315) frequentemente recorremos a otimizações manuais no código: definição explícita de esquema (*Schema Definition*) e seleção de colunas (*Column Pruning*). A análise do dataset `Yellow_Long` (CSV) revela que essas estratégias nem sempre trazem o retorno esperado.

```{python}
# Preparação dos dados para 4.4 - Otimização Manual
# Foco: Dataset Yellow_Long em CSV
df_opt = df_master[
    (df_master['Dataset'] == 'Yellow_Long') & 
    (df_master['Formato'] == 'CSV')
].copy()

# Pivotar para ter os Cenários lado a lado
tabela_opt = df_opt.pivot_table(
    index='Biblioteca', 
    columns='Cenario', 
    values='Tempo_Segundos',
    aggfunc='median'
).reset_index()

# Calcular a Redução Percentual de Tempo (Quanto % economizei?)
# Fórmula: 1 - (Tempo Otimizado / Tempo Base)
tabela_opt['Ganho_Tipagem_%'] = (1 - (tabela_opt['2_Com_Tipagem'] / tabela_opt['1_Leitura_Pura'])) * 100
tabela_opt['Ganho_Colunas_%'] = (1 - (tabela_opt['3_Apenas_Colunas'] / tabela_opt['1_Leitura_Pura'])) * 100

# Seleção e Ordenação
cols = ['Biblioteca', '1_Leitura_Pura', '2_Com_Tipagem', '3_Apenas_Colunas', 'Ganho_Tipagem_%', 'Ganho_Colunas_%']
print("--- Impacto da Otimização Manual (Tempo em Segundos e Ganho %) ---")
print(tabela_opt[cols].round(2).to_string(index=False))
```

|  |  |  |  |  |  |
|------------|------------|------------|------------|------------|------------|
| **Biblioteca** | **Tempo Original (s)** | **Tempo c/ Tipos (s)** | **Impacto Tipagem** | **Tempo Só Colunas (s)** | **Impacto Seleção** |
| **Polars** | 0.56 | 0.18 | ▲ 67.6% (Melhora) | 0.17 | ▲ 69.4% (Melhora) |
| **Pandas** | 3.48 | 7.19 | ▼ -106.9% (Piora) | 2.50 | ▲ 28.1% (Melhora) |
| **R Base** | 13.32 | 8.88 | ▲ 33.3% (Melhora) | 12.94 | ▲ 2.9% (Marginal) |
| **R Readr** | 12.43 | 8.49 | ▲ 31.7% (Melhora) | 12.54 | ▼ -0.9% (Piora) |

**1. O Paradoxo da Tipagem Manual** Definir os tipos de dados manualmente (`dtype={...}`) é uma prática comum para economizar memória, mas os testes mostram que ela pode **prejudicar severamente** a velocidade de leitura em certas bibliotecas.

-   **A Armadilha do Pandas:** Ao fornecer os tipos explicitamente, o tempo de leitura do Pandas **piorou 106%** (subindo de 3.48s para 7.19s). Isso ocorre porque a engine C do Pandas é altamente otimizada para inferência rápida. Ao forçar tipos, acionam-se validadores e conversores Python/Cython mais lentos, criando um gargalo de CPU desnecessário.

-   **A Necessidade do R:** Diferente do Pandas, tanto o R Base quanto o `readr` dependem da tipagem manual para performance. Ao evitar a "adivinhação" de tipos linha a linha, o R obteve um ganho de performance de **\~30%**.

-   **Polars Acelerado:** O Polars, já sendo o mais rápido (0.56s), conseguiu reduzir seu tempo para 0.18s com tipagem, mostrando que sua engine sabe aproveitar metadados para alocar memória de forma mais eficiente.

**2. Seleção de Colunas (Projection Pushdown)** A estratégia de ler apenas as colunas necessárias demonstrou ser a otimização mais segura e eficaz para ferramentas modernas.

-   **Polars (O Vencedor):** Obteve uma melhoria de **\~69%**, caindo para impressionantes **0.17s**. Isso confirma que o Polars implementa um verdadeiro *Projection Pushdown* no leitor de CSV, ignorando fisicamente o parsing de bytes das colunas não solicitadas.

-   **Pandas (Ganho Moderado):** Obteve um ganho de **28%**. Embora útil, o ganho é menor que no Polars, indicando que o Pandas ainda realiza parte do processamento da linha inteira antes de descartar os dados.

-   **R (Ineficaz em CSV):** A seleção de colunas teve impacto nulo ou negativo no R Base e `readr`. Isso sugere que, para arquivos de texto (CSV), essas bibliotecas leem a linha completa para a memória antes de filtrar as colunas, não economizando I/O ou CPU significativamente.

> **Veredito Prático:**
>
> -   Em **Pandas**: **Nunca** defina tipos manualmente visando velocidade (apenas memória). Use sempre `usecols` para filtrar colunas.
>
> -   Em **Polars**: Ambas as otimizações funcionam, mas a seleção de colunas é a "bala de prata".
>
> -   Em **R**: Se for obrigado a usar CSV, gaste tempo definindo o `colClasses` (tipos), pois é onde está o maior ganho.

```{python}
# Preparação dos dados para 4.5 - Foco em Seleção de Colunas (Projection Pushdown)
# Usando Dataset Yellow_Long (CSV)
df_cols = df_master[
    (df_master['Dataset'] == 'Yellow_Long') & 
    (df_master['Formato'] == 'CSV')
].copy()

tabela_cols = df_cols.pivot_table(
    index='Biblioteca', 
    columns='Cenario', 
    values='Tempo_Segundos',
    aggfunc='median'
).reset_index()

# Calcular a "Economia de Tempo"
tabela_cols['Economia_Tempo_s'] = tabela_cols['1_Leitura_Pura'] - tabela_cols['3_Apenas_Colunas']
tabela_cols['Eficiencia_Pushdown_%'] = (tabela_cols['Economia_Tempo_s'] / tabela_cols['1_Leitura_Pura']) * 100

# Formatação
tabela_final_a3 = tabela_cols[[
    'Biblioteca', 
    '1_Leitura_Pura', 
    '3_Apenas_Colunas', 
    'Eficiencia_Pushdown_%'
]].sort_values('Eficiencia_Pushdown_%', ascending=False)

# Ajuste visual
tabela_final_a3.columns = ['Biblioteca', 'Leitura Total (s)', 'Leitura Parcial (s)', 'Ganho de Performance (%)']
tabela_final_a3['Ganho de Performance (%)'] = tabela_final_a3['Ganho de Performance (%)'].apply(lambda x: f"▲ {x:.1f}%" if x > 0 else f"▼ {x:.1f}%")
tabela_final_a3['Leitura Total (s)'] = tabela_final_a3['Leitura Total (s)'].round(2)
tabela_final_a3['Leitura Parcial (s)'] = tabela_final_a3['Leitura Parcial (s)'].round(2)

print("--- Tabela 4.5: Eficiência de Projection Pushdown ---")
print(tabela_final_a3.to_markdown(index=False))
```

#### 4.5. Inteligência de Leitura: O Efeito *Projection Pushdown*

Uma das otimizações mais críticas em Big Data é o *Column Pruning* (podar colunas): instruir a ferramenta a ler apenas as colunas necessárias para a análise, ignorando o resto.

A tabela abaixo mede a eficiência de cada biblioteca em aplicar essa técnica no dataset CSV `Yellow_Long`. O indicador "Ganho de Performance" revela se a biblioteca realmente ignorou os dados desnecessários (*Projection Pushdown*) ou se leu tudo para filtrar depois.

|             |                   |                     |                          |
|-----------------|-----------------|------------------|----------------------|
| Biblioteca  | Leitura Total (s) | Leitura Parcial (s) | Ganho de Performance (%) |
| **Polars**  | 0.56              | 0.17                | ▲ 69.4%                  |
| **Pandas**  | 3.48              | 2.50                | ▲ 28.1%                  |
| **R Base**  | 13.32             | 12.94               | ▲ 2.9%                   |
| **R Readr** | 12.43             | 12.54               | ▼ -0.9%                  |

**Análise Técnica**

1.  **Polars e o *True Pushdown*:** O Polars apresentou uma redução de tempo drástica (**\~70%**). Isso comprova que sua engine de leitura é capaz de realizar *Projection Pushdown* físico em arquivos CSV. Ao identificar que apenas certas colunas são necessárias, o Polars pula o *parsing* (interpretação de texto para binário) das colunas ignoradas, economizando ciclos de CPU massivos. É uma leitura "inteligente".

2.  **Pandas e o *Post-Read Filter*:** O Pandas obteve um ganho moderado (**28%**). Embora útil, o ganho não é proporcional à redução de dados. Isso indica que o Pandas ainda precisa escanear a estrutura da linha e realizar alocações parciais antes de descartar as colunas indesejadas. O ganho vem mais da economia de memória RAM do que de processamento bruto.

3.  **R (Base e Readr): Leitura Cega:** As ferramentas de R apresentaram ganho nulo ou marginal. Isso sugere que, para o formato CSV, essas bibliotecas realizam a leitura completa do arquivo para a memória (ou buffer) antes de selecionar as colunas. Ou seja, pedir 2 colunas ou 20 colunas leva o mesmo tempo de processamento; a economia ocorre apenas na memória final ocupada, não na velocidade de ingestão.

> **Conclusão:** Para pipelines de alta performance onde apenas um subconjunto dos dados é necessário, o **Polars** é a única ferramenta que transforma essa redução lógica em ganho de velocidade real. Em R e Pandas, selecionar colunas ajuda na memória, mas não resolve gargalos de tempo de leitura em CSV.

### 5. Discussão: Developer Experience (DX)

Enquanto as seções anteriores focaram na eficiência computacional, esta discussão aborda a "Experiência do Desenvolvedor" (DX). A escolha de uma ferramenta não ocorre por nada: ela envolve um *trade-off* entre a velocidade de execução do código e a velocidade de escrita do mesmo.

**5.1. A Curva de Adoção do Polars** A transição do Pandas para o Polars não se comporta como uma simples troca de sintaxe, mas assemelha-se à de fato estar aprendendo uma nova linguagem. O Polars embora muito bem estruturado e robusto,impõe uma barreira de entrada significativa para quem possui memória muscular desenvolvida no estilo imperativo do Pandas (Caso de quem escreveu isso aqui).

Durante os experimentos, observou-se que o rigor do Polars quanto à tipagem (definir o schema (tiposde colunas)) de dados atua como uma faca de dois gumes que pode ser um pouco chato no começo. Em datasets volumosos (Giga Yellow), a inferência de tipos estrita gerou exceções que impediram a leitura imediata, exigindo intervenções manuais de configuração antes mesmo do processamento iniciar. Em contrapartida, a permissividade do Pandas permitiu uma ingestão inicial mais fluida ("plug-and-play"), ainda que ao custo de performance posterior. Na nossa concepção do grupo, o polars de fato é uma linguagem muito mais robusta quando se está trabalhando em um ecossitema que exige um maior nível de profissionalidade e eficiência do código importa mais do que a facilidade de escrita e de utilização. Porém, (Fala do Diego) eu ainda continuo importanto o pandas toda vez que abro um arquivo em python novo, é muito mais prático para tarefas que não justificam o ganho de eficiência mostrada anteriormente.

**5.2. A Coesão do Ecossistema R** Diferente da fragmentação que por vezes ocorre ao integrar bibliotecas de alta performance em outros ambientes, a utilização do `readr` e `arrow` no ecossistema R demonstrou consistência. A integração dessas ferramentas (backend C++, isso justifica a alta velocidade)com a sintaxe do R manteve-se transparente, não exigindo alterações drásticas no fluxo de trabalho habitual de um estatístico.

**5.3. Considerações sobre o Aprendizado** A análise qualitativa sugere que a dificuldade associada ao Polars. A arquitetura da biblioteca força boas práticas de engenharia de dados desde a leitura. Conclui-se que, se o Polars fosse a primeira ferramenta apresentada a um estudante, a percepção de dificuldade seria mitigada, estabelecendo um padrão mental mais eficiente desde o início. O esforço de migração gera uma recompensa assimétrica: o custo cognitivo inicial é alto, mas o ganho de escalabilidade e a redução de dívida técnica no longo prazo são substanciais. No caso de R, não há nenhuma justificativa em utilizar a Base do R em contrapartida ao ReadR, ambos tem uma usabilidade muito parecida e o ganho de performance é muito grande entre ambas. Entre a seleção de R e Python, é uma coisa muito pessoal e depende muito da área de atuação do Cientista de Dados/Estatístico, porém, se a necessidade é o "Importador de bibliotecas mais rápido" sempre opte pelo Polars.\

**5.4. O Declínio do CSV** A persistência do CSV como padrão na indústria revela um conflito entre legibilidade humana e eficiência de máquina. Embora o CSV ofereça a vantagem da facilidade de uso, podendo ser aberto desde o Bloco de Notas até o Excel, ele transfere a vantagem da estruturação simples para o momento da leitura (que precisa decodificar todo o arquivo).

Sob a ótica da Experiência do Desenvolvedor (DX), o formato Parquet se mostrou não apenas superior em performance, mas também em robustez. Grande parte da fricção relatada com o Polars (a necessidade de configurar tipos manuais e tratar erros de inferência) desaparece ao utilizar Parquet. Diferente do CSV, que é "esquecido" de sua estrutura a cada salvamento, o Parquet preserva os metadados e o esquema (*schema*) do dataset. Isso significa que um arquivo salvo como `Int64` será lido como `Int64`, eliminando a adivinhação custosa e propensa a erros que as bibliotecas precisam realizar a cada leitura de texto.

A análise sugere uma mudança de paradigma no fluxo de trabalho: o CSV deve ser relegado estritamente às pontas do pipeline (recebimento de dados brutos de terceiros ou entrega final para relatórios ou para o cliente). Para todas as etapas intermediárias de armazenamento e processamento, o Parquet elimina ambiguidades técnicas, agindo como um contrato de dados estável entre diferentes sessões e ferramentas.

Utilize Parquet!

**5.5. O Júlia como uma outra alternativa** O Julia se tornou uma ótima alternativa para quem se interessaem aprender mais sobre outra linguagem e ter o desempenho muito rápido. Com uma sintaxe não muito complexa se mostra uma alternativa interessante que resolver o problema que tanto o R quando o python tem.

### 6. Guia Prático de Seleção (o motivador de todo trabalho)

### . A Regra do Novo Padrão

> **"Vai começar agora? Comece com Polars."** Se o seu dado cabe na memória RAM, o Polars deve ser sua primeira escolha. Aprender a sintaxe dele é chato no começo? É. Mas ele é 4x mais rápido que o Pandas e te protege de erros bobos de tipagem. O investimento se paga rápido.

### 2. A Regra do Legado

> **"Não conserte o que não está lento."** Se você tem um script em Pandas que roda em 10 segundos, não perca 2 horas reescrevendo ele em Polars para ganhar 5 segundos. O Pandas ainda é ótimo para protótipos rápidos e datasets pequenos (abaixo de 500MB). Use o tempo para analisar dados, não para refatorar código.

### 3. A Regra do Formato!

> **"CSV é para transporte, Parquet é para trabalho."** A maior otimização que você pode fazer não é trocar de linguagem, é trocar de arquivo. Nossos testes mostraram ganhos de até **28x** (com Julia) só de sair do CSV para o Parquet. Use CSV só se o cliente exigir; internamente, salve tudo em Parquet.

### 4. A Regra da Otimização

> **"Selecione colunas sempre. Tipagem manual? Depende."** Se for obrigado a ler um CSV gigante:

-   **Sempre** diga para a biblioteca quais colunas você quer (`select` ou `usecols`). Isso economiza muita memória.

-   **Cuidado no Pandas:** Definir os tipos na mão (`int`, `float`) fez o Pandas ficar **mais lento** nos nossos testes. Deixe ele se virar sozinho.

-   **No Polars, R e Julia:** Definir tipos na mão ajuda e deixa tudo mais rápido.

### 5. A Regra do Usuário de R

> **"Aposente o `read.csv`."** Se você usa R, esqueça que a função nativa `read.csv` existe. Ela é lenta demais. Use sempre os pacotes `readr` ou `arrow`. Com eles, o R fica tão competitivo quanto o Python.

### 6. A Regra da Julia (O Desafiante)

> **"Julia é para quem tem pressa no fim, e paciência no começo."** A Julia foi a campeã absoluta na leitura de Parquet (8 segundos), batendo todo mundo. O preço? O tempo de "aquecimento" (compilação JIT) na primeira rodada. Se o seu pipeline é pesado e recorrente, migrar para Julia vai te dar a maior performance possível. Se for um script rápido de uma vez só, o tempo de compilação pode não valer a pena.

### 7. A Guerra das Linguagens (Python vs. R vs. Julia)

> **"Não existe bala de prata, existe a ferramenta certa para o formato certo."** Nossos testes provaram que a "guerra" depende do terreno:

-   **No CSV (Força Bruta):** O **Python (com Polars)** ganha de lavada. É a melhor ferramenta para mastigar texto sujo.

-   **No Parquet (Leitura Otimizada):** A **Julia** assumiu a ponta, com o **R (readr)** e **Polars** logo atrás.

-   **Resumo:** Se o dado já está em Parquet, a linguagem não importa tanto (todas são rápidas). Use a que você gosta mais. Se for CSV, vá de Polars.

### 7. Conclusão: Eficiência como Sobrevivência no Limite do Hardware

Este estudo iniciou-se com uma pergunta sobre velocidade (**"Quem é mais rápido?"**), mas os dados revelaram uma questão mais crítica sobre viabilidade (**"Quem consegue terminar a tarefa?"**).

Ao submeter um notebook de alta performance (i7, 16GB RAM) a um dataset de escala Gigabyte, observamos o fenômeno do **"Muro do Hardware"**. Todas as bibliotecas testadas atingiram o teto físico de **15.71 GB** de memória RAM no teste de estresse. Nesse cenário limite, a eficiência da ferramenta deixa de ser uma questão de economizar segundos e passa a determinar se o workflow é executável ou se resultará em um erro fatal de *Out of Memory* (OOM).

#### A Sobrevivência Local

Para o Cientista de Dados que opera localmente, fora de clusters infinitos na nuvem, a conclusão é clara:

1.  **Otimização é Obrigatória:** O uso de formatos colunares (**Parquet**) e técnicas de leitura seletiva (*Projection Pushdown*) deixaram de ser apenas "boas práticas" para se tornarem requisitos funcionais. São os únicos mecanismos que permitem processar volumes de dados superiores à memória física disponível, mitigando o gargalo de *Swap* em disco.

2.  **A Hegemonia das Novas Arquiteturas:** O estudo comprovou a superioridade das ferramentas modernas sobre as legadas.

    -   **No caos do CSV:** O **Polars** provou ser a ferramenta mais resiliente, gerenciando memória agressivamente para entregar performance mesmo sob saturação, algo que as engines *single-core* (Pandas e R Base) não conseguiram acompanhar.

    -   **Na ordem do Parquet:** A **Julia** demonstrou que, quando o dado está estruturado, sua arquitetura *Just-in-Time* é imbatível, liderando o ranking de velocidade pura.

#### O Horizonte de Escalabilidade

Embora ferramentas como Polars, Julia e `readr` estendam significativamente a vida útil do hardware local, permitindo análises de Big Data em um laptop, existe um limite físico intransponível.

Quando o volume de dados ultrapassa consistentemente a barreira da RAM (mesmo com todas as otimizações aplicadas) ou quando o tempo de processamento inviabiliza a iteração ágil, a solução deixa de ser "trocar a biblioteca" e passa a ser **"trocar a infraestrutura"**. Neste ponto, os conceitos validados aqui — preferência por Parquet, execução *Lazy* e Tipagem Estrita — tornam-se a base necessária para migrar para frameworks distribuídos (como Apache Spark ou Dask), onde a lógica de eficiência permanece a mesma, mas a escala torna-se horizontal.
