<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Análise do Benchmark de compração entre Julia, Python e R em importação de dados</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="analise_benchmark_files/libs/clipboard/clipboard.min.js"></script>
<script src="analise_benchmark_files/libs/quarto-html/quarto.js"></script>
<script src="analise_benchmark_files/libs/quarto-html/popper.min.js"></script>
<script src="analise_benchmark_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="analise_benchmark_files/libs/quarto-html/anchor.min.js"></script>
<link href="analise_benchmark_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="analise_benchmark_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="analise_benchmark_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="analise_benchmark_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="analise_benchmark_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Análise do Benchmark de compração entre Julia, Python e R em importação de dados</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> polars <span class="im">as</span> pl</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(JuliaCall)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Instalar o pacote PrettyTables dentro do ambiente Julia</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">julia_eval</span>(<span class="st">'import Pkg; Pkg.add("PrettyTables")'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Julia version 1.12.1 at location C:\Users\dipis\AppData\Local\Programs\JULIA-~1.1\bin will be used.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading setup script for JuliaCall...</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Finish loading setup script for JuliaCall.</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>NULL</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode julia code-with-copy"><code class="sourceCode julia"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">using</span> <span class="bu">CSV</span>, <span class="bu">DataFrames</span>, <span class="bu">Statistics</span>, <span class="bu">PrettyTables</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co">#using Plots </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="integrantes-do-grupo" class="level2">
<h2 class="anchored" data-anchor-id="integrantes-do-grupo">1. Integrantes do Grupo</h2>
<p>Diego Pires Silva, Henry Koiti Honda e Joaquim Bertoldi Nucci</p>
<section id="motivação-e-introdução" class="level3">
<h3 class="anchored" data-anchor-id="motivação-e-introdução">2. Motivação e introdução</h3>
<p>Todo cientista de dados conhece a dor: você dá o “play” no código para carregar um arquivo e fica esperando minutos,às vezes horas, olhando para a tela enquanto a memória RAM do computador vai para o limite.</p>
<p>O problema é claro: os dados estão cada vez maiores, mas nossos notebooks continuam, na média, com os mesmos 16GB de RAM. Ferramentas clássicas que aprendemos na faculdade, como o Pandas ou o comando básico do R, foram criadas anos atrás e muitas vezes vão penar quando o arquivo é grande demais.</p>
<p>Hoje, fala-se muito que o <strong>Polars</strong> e o formato <strong>Parquet</strong> são a solução mágica para isso. Mas será que são mesmo?</p>
<p>A motivação deste estudo é simples: colocar essas ferramentas à prova na prática. Quero descobrir se vale a pena gastar tempo aprendendo uma nova biblioteca para ganhar velocidade, e se é possível trabalhar com grandes volumes de dados no meu próprio notebook, sem precisar de computadores da NASA ou pagar caro por nuvem.</p>
</section>
<section id="metodologia-experimental" class="level3">
<h3 class="anchored" data-anchor-id="metodologia-experimental">3. Metodologia Experimental</h3>
<p>O experimento foi estruturado para avaliar o desempenho das bibliotecas em um cenário de restrição de recursos, representativo de uma estação de trabalho local (notebook da maioria dos aspirantes à estatísticos ou cientistas de dados como nós!) , isolando variáveis de hardware e software que poderiam introduzir ruído nas medições.</p>
<p><strong>3.1. Infraestrutura:</strong> Os experimentos foram conduzidos em um notebook MSI Cyborg 14, operando sobre Windows 11 nativo. Para evitar a variabilidade introduzida pelo escalonamento de frequência da CPU e gerenciamento de energia, o equipamento foi mantido conectado à fonte de alimentação ininterrupta (no carregador), com o perfil de energia do sistema operacional fixado em “Alta Performance”. Durante as baterias de testes, processos concorrentes foram encerrados, mantendo-se ativos estritamente o ambiente de execução (R/Python) e o diretório de dados, visando minimizar a interferência no consumo de qualquer outra coisa que estivesse aberta no computador. e</p>
<p>As especificações de hardware incluem um processador Intel Core i7, GPU NVIDIA RTX 4050 e 16GB de memória RAM. Este último componente define o teto físico de operação para as bibliotecas <em>in-memory</em>, servindo como principal variável de estresse nos testes de volume.</p>
<p><strong>3.2. Dados e Fontes</strong> A seleção dos datasets buscou cobrir três vetores distintos de complexidade computacional:</p>
<ul>
<li><p><strong>Volume e Extensão (Giga &amp; Long):</strong> Utilizou-se os dados históricos de viagens de táxi de Nova Iorque (<em>NYC Taxi &amp; Limousine Commission - TLC Trip Record Data</em>). O dataset “Giga” avalia a capacidade de vazão (<em>throughput</em>) e gerenciamento de memória próxima à saturação, enquanto o recorte “Long” foca na eficiência de processamento vetorial em milhões de linhas. São referências em benchmarks desse tipo.</p></li>
<li><p><strong>Dimensionalidade (Wide):</strong> Para avaliar o <em>overhead</em> de processamento de colunas e inferência de tipos heterogêneos, utilizou-se o <em>Stack Overflow Annual Developer Survey</em>, caracterizado por sua estrutura larga e mix de dados numéricos e textuais.</p></li>
</ul>
<p><strong>3.3. Versionamento e tecnologias:</strong> A reprodutibilidade dos resultados fundamenta-se nas versões específicas das bibliotecas, dado que implementações recentes (como por exemplo, o backend PyArrow no Pandas 2.0) alteram significativamente a performance de leitura.</p>
<ul>
<li><p><strong>Ambiente Python (3.13):</strong> Polars 1.33.1, Pandas 2.2.2, PyArrow 19.0.0 e NumPy 2.2.2.</p></li>
<li><p><strong>Ambiente R (4.4.3):</strong> readr 2.1.5, arrow 21.0.0.1, dplyr 1.1.4 e glue 1.8.0.</p></li>
<li><p><strong>Ambiente Julia (1.2.0)</strong></p></li>
</ul>
<p><strong>3.4. Protocolo de Medição</strong> Cada cenário experimental, definido pela Biblioteca, Formato e tipo de dataset, foi submetido a 10 execuções consecutivas. A métrica de avaliação adotada foi a mediana dos tempos de execução, estratégia utilizada para neutralizar <em>outliers</em> decorrentes de latências momentâneas do sistema operacional ou do disco. Os logs de consumo de memória foram capturados em intervalos de milissegundos para identificar picos de uso e o comportamento de <em>Garbage Collection</em>.</p>
<p>Foram realizadas 338 amostras de importação desses conjuntos de dados separados em A1, A2 e A3 em que A1 é a imporação comum que foi importado com todas as bibliotecas, csv e parquet. A2 importação definindo um schema prévio que foi realizadas apenas em CSV para o Dataset Yellowlong para todas as bibliotecas. E A3 que é a análise dos conjuntos de dados “removendo” algumas colunas na leitura que foi realizada da mesma forma que o A2.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df_master <span class="op">=</span> pd.read_csv(<span class="st">"MASTER_BENCHMARK_DATA.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filtro: Vamos olhar apenas para o Cenário 1 (Leitura Pura) para ser justo</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Agrupamento pelas variáveis categóricas</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>tabela_descritiva <span class="op">=</span> df_master.groupby([<span class="st">'Dataset'</span>, <span class="st">'Cenario'</span>, <span class="st">'Formato'</span>, <span class="st">'Biblioteca'</span>]).agg(</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    Tempo_Medio_s<span class="op">=</span>(<span class="st">'Tempo_Segundos'</span>, <span class="st">'mean'</span>),</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    Tempo_Min_s<span class="op">=</span>(<span class="st">'Tempo_Segundos'</span>, <span class="st">'min'</span>),</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    Tempo_Std<span class="op">=</span>(<span class="st">'Tempo_Segundos'</span>, <span class="st">'std'</span>),  <span class="co"># Indica instabilidade</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    RAM_Pico_GB<span class="op">=</span>(<span class="st">'RAM_Pico_GB'</span>, <span class="st">'max'</span>),   <span class="co"># O pior caso de RAM é o que importa para evitar OOM</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    Amostras<span class="op">=</span>(<span class="st">'Iteracao'</span>, <span class="st">'count'</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Cálculo do Coeficiente de Variação (CV%) - para medir estabilidade percentual</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># CV &lt; 5% = Muito estável | CV &gt; 20% = Instável</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>tabela_descritiva[<span class="st">'Estabilidade_CV_Pct'</span>] <span class="op">=</span> (</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    tabela_descritiva[<span class="st">'Tempo_Std'</span>] <span class="op">/</span> tabela_descritiva[<span class="st">'Tempo_Medio_s'</span>]</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Ordenar para facilitar leitura</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>tabela_descritiva <span class="op">=</span> tabela_descritiva.sort_values(by<span class="op">=</span>[<span class="st">'Dataset'</span>, <span class="st">'Cenario'</span>, <span class="st">'Tempo_Medio_s'</span>])</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Exibir tabela formatada</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Tabela Descritiva Geral ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Tabela Descritiva Geral ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabela_descritiva)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               Dataset           Cenario  ... Amostras Estabilidade_CV_Pct
4          Giga_Yellow    1_Leitura_Pura  ...       10            7.975492
7          Giga_Yellow    1_Leitura_Pura  ...       12           10.615143
6          Giga_Yellow    1_Leitura_Pura  ...       11           12.528681
5          Giga_Yellow    1_Leitura_Pura  ...       11            9.240769
2          Giga_Yellow    1_Leitura_Pura  ...       10           16.509298
0          Giga_Yellow    1_Leitura_Pura  ...       10           14.062038
1          Giga_Yellow    1_Leitura_Pura  ...       11           10.582466
3          Giga_Yellow    1_Leitura_Pura  ...       11           12.204952
15  StackOverflow_Wide    1_Leitura_Pura  ...       11           18.219382
14  StackOverflow_Wide    1_Leitura_Pura  ...       11            8.426501
16  StackOverflow_Wide    1_Leitura_Pura  ...       10           37.145399
17  StackOverflow_Wide    1_Leitura_Pura  ...       10           38.623433
10  StackOverflow_Wide    1_Leitura_Pura  ...       11           13.261459
13  StackOverflow_Wide    1_Leitura_Pura  ...       10           20.282599
9   StackOverflow_Wide    1_Leitura_Pura  ...       11            1.789968
12  StackOverflow_Wide    1_Leitura_Pura  ...       12           16.461781
11  StackOverflow_Wide    1_Leitura_Pura  ...       10            2.480875
8   StackOverflow_Wide    1_Leitura_Pura  ...       10            6.556113
25         Yellow_Long    1_Leitura_Pura  ...        1                 NaN
23         Yellow_Long    1_Leitura_Pura  ...       10           17.211761
26         Yellow_Long    1_Leitura_Pura  ...       10            8.277464
27         Yellow_Long    1_Leitura_Pura  ...       11            6.526442
20         Yellow_Long    1_Leitura_Pura  ...       22           67.514503
24         Yellow_Long    1_Leitura_Pura  ...       10           69.425984
19         Yellow_Long    1_Leitura_Pura  ...       10            2.421689
22         Yellow_Long    1_Leitura_Pura  ...       11            2.495329
21         Yellow_Long    1_Leitura_Pura  ...       11            4.725231
18         Yellow_Long    1_Leitura_Pura  ...       10           62.542737
29         Yellow_Long     2_Com_Tipagem  ...       11            5.933844
28         Yellow_Long     2_Com_Tipagem  ...       11            1.144533
30         Yellow_Long     2_Com_Tipagem  ...       11            2.724342
31         Yellow_Long     2_Com_Tipagem  ...       23           62.862519
33         Yellow_Long  3_Apenas_Colunas  ...       11           19.155183
32         Yellow_Long  3_Apenas_Colunas  ...       11            1.600141
35         Yellow_Long  3_Apenas_Colunas  ...       11            7.624724
34         Yellow_Long  3_Apenas_Colunas  ...       11            3.705271

[36 rows x 10 columns]</code></pre>
</div>
</div>
</section>
</section>
<section id="comparação-entre-performance-a1" class="level1">
<h1>4.1 Comparação entre performance A1</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correção: Usando 'Tempo_Segundos' (coluna original) e calculando a média na hora</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df_41 <span class="op">=</span> df_master[df_master[<span class="st">'Cenario'</span>] <span class="op">==</span> <span class="st">'1_Leitura_Pura'</span>].copy()</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivotagem</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>tabela_formatos <span class="op">=</span> df_41.pivot_table(</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>[<span class="st">'Dataset'</span>, <span class="st">'Biblioteca'</span>], </span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span><span class="st">'Formato'</span>, </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    values<span class="op">=</span><span class="st">'Tempo_Segundos'</span>,  <span class="co"># &lt;--- Nome corrigido aqui</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    aggfunc<span class="op">=</span><span class="st">'mean'</span>            <span class="co"># &lt;--- O Python calcula a média aqui</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Cálculo do Speedup (Aceleração)</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Garante que as colunas existam antes de calcular (caso falte algum dado)</span></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'CSV'</span> <span class="kw">in</span> tabela_formatos.columns <span class="kw">and</span> <span class="st">'Parquet'</span> <span class="kw">in</span> tabela_formatos.columns:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    tabela_formatos[<span class="st">'Speedup_X'</span>] <span class="op">=</span> tabela_formatos[<span class="st">'CSV'</span>] <span class="op">/</span> tabela_formatos[<span class="st">'Parquet'</span>]</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"AVISO: Faltam dados de CSV ou Parquet para calcular o Speedup."</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Limpeza e Exibição</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>tabela_output <span class="op">=</span> tabela_formatos.dropna(subset<span class="op">=</span>[<span class="st">'Speedup_X'</span>]).sort_values(</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    by<span class="op">=</span>[<span class="st">'Dataset'</span>, <span class="st">'Speedup_X'</span>], </span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    ascending<span class="op">=</span>[<span class="va">True</span>, <span class="va">False</span>]</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'Dataset'</span>, <span class="st">'Biblioteca'</span>, <span class="st">'CSV'</span>, <span class="st">'Parquet'</span>, <span class="st">'Speedup_X'</span>]</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Tabela para Análise 4.1 ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Tabela para Análise 4.1 ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># O to_string garante que o Pandas não corte as linhas no terminal</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabela_output[cols].<span class="bu">round</span>(<span class="dv">2</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>           Dataset Biblioteca    CSV  Parquet  Speedup_X
       Giga_Yellow      Julia 177.13     8.23      21.52
       Giga_Yellow     Pandas 201.79    12.16      16.60
       Giga_Yellow     Polars  51.23     9.41       5.44
StackOverflow_Wide     R_Base   2.08     0.21      10.02
StackOverflow_Wide     Polars   0.49     0.06       8.76
StackOverflow_Wide     Pandas   1.06     0.13       8.15
StackOverflow_Wide    R_Readr   1.68     0.22       7.77
StackOverflow_Wide      Julia   3.65     0.69       5.27
       Yellow_Long      Julia  14.48     0.51      28.18
       Yellow_Long     R_Base  13.39     0.53      25.03
       Yellow_Long    R_Readr  12.53     0.55      22.98
       Yellow_Long     Polars   0.55     0.16       3.44
       Yellow_Long     Pandas   3.48     1.19       2.92</code></pre>
</div>
</div>
<ul>
<li><p><strong>1. A Vitória da Julia no Parquet (Giga)</strong> A grande surpresa do teste Giga foi a performance da Julia no formato Parquet. Com um tempo de <strong>8.23 segundos</strong>, a Julia foi a <strong>campeã absoluta de leitura binária</strong>, superando o Polars (9.41s) e o Pandas (12.16s). Isso comprova que a arquitetura da linguagem é extremamente eficiente para I/O de dados estruturados, justificando sua fama em computação de alta performance.</p>
<p><strong>2. A Hegemonia do Polars no CSV</strong> No formato CSV, o cenário se inverte. Enquanto Julia e Pandas levaram cerca de <strong>3 minutos</strong> (177s e 201s) para ler o arquivo gigante, o Polars terminou a tarefa em <strong>51 segundos</strong>.</p>
<ul>
<li><strong>Diagnóstico:</strong> O leitor de CSV da Julia (<code>CSV.jl</code>), embora ligeiramente mais rápido que o Pandas, ainda sofre do mesmo gargalo: o custo de converter texto para número. O Polars vence aqui por sua engine especializada em <em>multithreading</em> agressivo para texto.</li>
</ul>
<p><strong>3. O Maior Ganho de Migração (Speedup)</strong> A Julia apresentou o maior benefício ao trocar de formato: um ganho de <strong>21.5x</strong> no Giga e <strong>28x</strong> no dataset Longo.</p>
<ul>
<li><strong>Interpretação:</strong> Para usuários de Julia (e R), abandonar o CSV não é opcional, é uma questão de sobrevivência. A diferença entre esperar 3 minutos (CSV) e esperar 8 segundos (Parquet) altera completamente a fluidez do trabalho. No Polars, o ganho é “menor” (5x) apenas porque ele já era excepcionalmente rápido no CSV.</li>
</ul>
<p><strong>4. A Instabilidade no “Wide”</strong> Vale notar que no dataset <em>StackOverflow</em> (muitas colunas), a Julia teve um desempenho inferior (3.65s no CSV), perdendo para R Base e Pandas. Isso sugere que a compilação JIT (tempo de inicialização da Julia) ou o overhead de gerenciar muitas colunas textuais tem um peso maior em arquivos menores, onde a “força bruta” da linguagem não tem tempo de brilhar.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparação dos dados para 4.2 - Foco no Dataset Giga (Estresse)</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Agrupando por Biblioteca e Formato para pegar a Mediana do Tempo e o Máximo de RAM</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>df_giga_agg <span class="op">=</span> df_master[</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Dataset'</span>] <span class="op">==</span> <span class="st">'Giga_Yellow'</span>) <span class="op">&amp;</span> </span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Cenario'</span>] <span class="op">==</span> <span class="st">'1_Leitura_Pura'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>].groupby([<span class="st">'Formato'</span>, <span class="st">'Biblioteca'</span>]).agg(</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    Tempo_Mediano_s<span class="op">=</span>(<span class="st">'Tempo_Segundos'</span>, <span class="st">'median'</span>),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    RAM_Pico_GB<span class="op">=</span>(<span class="st">'RAM_Pico_GB'</span>, <span class="st">'max'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabela A: Ranking CSV</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>ranking_csv <span class="op">=</span> df_giga_agg[df_giga_agg[<span class="st">'Formato'</span>] <span class="op">==</span> <span class="st">'CSV'</span>].sort_values(<span class="st">'Tempo_Mediano_s'</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Adiciona coluna de comparação (Quantas vezes mais lento que o 1º lugar)</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>melhor_tempo_csv <span class="op">=</span> ranking_csv[<span class="st">'Tempo_Mediano_s'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>ranking_csv[<span class="st">'X_Vezes_Mais_Lento'</span>] <span class="op">=</span> ranking_csv[<span class="st">'Tempo_Mediano_s'</span>] <span class="op">/</span> melhor_tempo_csv</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Tabela B: Ranking Parquet</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>ranking_parquet <span class="op">=</span> df_giga_agg[df_giga_agg[<span class="st">'Formato'</span>] <span class="op">==</span> <span class="st">'Parquet'</span>].sort_values(<span class="st">'Tempo_Mediano_s'</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>melhor_tempo_parquet <span class="op">=</span> ranking_parquet[<span class="st">'Tempo_Mediano_s'</span>].iloc[<span class="dv">0</span>]</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>ranking_parquet[<span class="st">'X_Vezes_Mais_Lento'</span>] <span class="op">=</span> ranking_parquet[<span class="st">'Tempo_Mediano_s'</span>] <span class="op">/</span> melhor_tempo_parquet</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Ranking Giga CSV (Processamento Puro) ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Ranking Giga CSV (Processamento Puro) ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ranking_csv[[<span class="st">'Biblioteca'</span>, <span class="st">'Tempo_Mediano_s'</span>, <span class="st">'RAM_Pico_GB'</span>, <span class="st">'X_Vezes_Mais_Lento'</span>]].<span class="bu">round</span>(<span class="dv">2</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Biblioteca  Tempo_Mediano_s  RAM_Pico_GB  X_Vezes_Mais_Lento
    Polars            54.82        15.71                1.00
     Julia           164.52     15706.00                3.00
    R_Base           201.72     15709.00                3.68
    Pandas           202.37     15709.00                3.69</code></pre>
</div>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Ranking Giga Parquet (IO Puro) ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Ranking Giga Parquet (IO Puro) ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ranking_parquet[[<span class="st">'Biblioteca'</span>, <span class="st">'Tempo_Mediano_s'</span>, <span class="st">'RAM_Pico_GB'</span>, <span class="st">'X_Vezes_Mais_Lento'</span>]].<span class="bu">round</span>(<span class="dv">2</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Biblioteca  Tempo_Mediano_s  RAM_Pico_GB  X_Vezes_Mais_Lento
   R_Readr             8.27     15705.00                1.00
     Julia             8.45      7373.00                1.02
    Polars             9.85        15.71                1.19
    Pandas            11.68     15709.00                1.41</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparação dos dados para 4.3 - Eficiência de Memória</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Vamos comparar o comportamento em CSV, onde a gestão de memória é mais crítica</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>df_memoria <span class="op">=</span> df_master[</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Cenario'</span>] <span class="op">==</span> <span class="st">'1_Leitura_Pura'</span>) <span class="op">&amp;</span> </span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Formato'</span>] <span class="op">==</span> <span class="st">'CSV'</span>) <span class="op">&amp;</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Dataset'</span>].isin([<span class="st">'Yellow_Long'</span>, <span class="st">'Giga_Yellow'</span>]))</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>].groupby([<span class="st">'Dataset'</span>, <span class="st">'Biblioteca'</span>]).agg(</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    RAM_Pico_GB<span class="op">=</span>(<span class="st">'RAM_Pico_GB'</span>, <span class="st">'max'</span>),</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    Tempo_Mediano_s<span class="op">=</span>(<span class="st">'Tempo_Segundos'</span>, <span class="st">'median'</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivotar para comparar os Datasets lado a lado</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>tabela_memoria <span class="op">=</span> df_memoria.pivot_table(</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">'Biblioteca'</span>, </span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span><span class="st">'Dataset'</span>, </span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    values<span class="op">=</span><span class="st">'RAM_Pico_GB'</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular o "Overhead" (Se possível, mas vamos focar nos valores absolutos)</span></span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Pico de Uso de Memória (GB) - CSV ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Pico de Uso de Memória (GB) - CSV ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabela_memoria.<span class="bu">round</span>(<span class="dv">2</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Biblioteca  Giga_Yellow  Yellow_Long
     Julia     15706.00      10227.0
    Pandas     15709.00      12828.0
    Polars        15.71      14466.0
    R_Base     15709.00       9012.0
   R_Readr          NaN      10305.0</code></pre>
</div>
</div>
<section id="eficiência-de-memória-e-limites-de-hardware" class="level3">
<h3 class="anchored" data-anchor-id="eficiência-de-memória-e-limites-de-hardware">4.3. Eficiência de Memória e Limites de Hardware</h3>
<p>A tabela do consumo de memória RAM revela o limite físico da infraestrutura de teste e a eficiência de gerenciamento de cada biblioteca. A tabela abaixo compara o pico de memória exigido para carregar os datasets em formato CSV.</p>
<section id="análise-o-muro-dos-16gb" class="level4">
<h4 class="anchored" data-anchor-id="análise-o-muro-dos-16gb">Análise: O Muro dos 16GB</h4>
<p><strong>1. Diagnóstico de Saturação (Dataset Giga)</strong> No cenário de estresse, <strong>todas</strong> as bibliotecas atingiram o teto de <strong>15.71 GB</strong>. Isso comprova que o hardware foi o fator limitante.</p>
<ul>
<li><p><strong>Consequência:</strong> O esgotamento da RAM física forçou o sistema operacional a usar <em>Swap</em> (disco como memória), degradando drasticamente a performance de Pandas, R e Julia (tempos &gt; 170s).</p></li>
<li><p><strong>A Exceção:</strong> O Polars, mesmo saturando a memória, conseguiu finalizar a tarefa em 51s. Sua arquitetura <em>Lazy</em> gerenciou o <em>Swap</em> de forma muito mais eficiente que os concorrentes.</p></li>
</ul>
<p><strong>2. O Custo da Velocidade (Dataset Long)</strong> No cenário onde a memória <em>não</em> acabou, o comportamento natural das engines se revelou:</p>
<ul>
<li><p><strong>R Base e Julia (Eficiência):</strong> Foram os mais econômicos (~9GB e ~10GB). A Julia demonstrou um gerenciamento de memória superior ao Pandas, consumindo 20% menos RAM para a mesma tarefa.</p></li>
<li><p><strong>Polars (Consumo Agressivo):</strong> Foi o que mais consumiu memória (14.5 GB). Isso confirma que o Polars troca espaço por velocidade: ele aloca grandes <em>buffers</em> para alimentar seus núcleos paralelos.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Insight Prático:</strong> Velocidade custa memória. Se você tem pouca RAM disponível (ex: containers Docker pequenos de 4GB), o <strong>R Base</strong> ou <strong>Julia</strong> são escolhas mais seguras contra travamentos (<em>crashes</em>). O <strong>Polars</strong> deve ser usado quando há memória sobrando para “queimar” em troca de performance máxim</p>
</blockquote>
</section>
<section id="otimização-manual-esforço-vs.-recompensa" class="level4">
<h4 class="anchored" data-anchor-id="otimização-manual-esforço-vs.-recompensa">4.4. Otimização Manual: Esforço vs.&nbsp;Recompensa</h4>
<p>Além da escolha da ferramenta, nós (como bons alunos de ME315) frequentemente recorremos a otimizações manuais no código: definição explícita de esquema (<em>Schema Definition</em>) e seleção de colunas (<em>Column Pruning</em>). A análise do dataset <code>Yellow_Long</code> (CSV) revela que essas estratégias nem sempre trazem o retorno esperado.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparação dos dados para 4.4 - Otimização Manual</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Foco: Dataset Yellow_Long em CSV</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>df_opt <span class="op">=</span> df_master[</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Dataset'</span>] <span class="op">==</span> <span class="st">'Yellow_Long'</span>) <span class="op">&amp;</span> </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    (df_master[<span class="st">'Formato'</span>] <span class="op">==</span> <span class="st">'CSV'</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Pivotar para ter os Cenários lado a lado</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>tabela_opt <span class="op">=</span> df_opt.pivot_table(</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span><span class="st">'Biblioteca'</span>, </span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span><span class="st">'Cenario'</span>, </span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    values<span class="op">=</span><span class="st">'Tempo_Segundos'</span>,</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    aggfunc<span class="op">=</span><span class="st">'median'</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>).reset_index()</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcular a Redução Percentual de Tempo (Quanto % economizei?)</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Fórmula: 1 - (Tempo Otimizado / Tempo Base)</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>tabela_opt[<span class="st">'Ganho_Tipagem_%'</span>] <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> (tabela_opt[<span class="st">'2_Com_Tipagem'</span>] <span class="op">/</span> tabela_opt[<span class="st">'1_Leitura_Pura'</span>])) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>tabela_opt[<span class="st">'Ganho_Colunas_%'</span>] <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> (tabela_opt[<span class="st">'3_Apenas_Colunas'</span>] <span class="op">/</span> tabela_opt[<span class="st">'1_Leitura_Pura'</span>])) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Seleção e Ordenação</span></span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="st">'Biblioteca'</span>, <span class="st">'1_Leitura_Pura'</span>, <span class="st">'2_Com_Tipagem'</span>, <span class="st">'3_Apenas_Colunas'</span>, <span class="st">'Ganho_Tipagem_%'</span>, <span class="st">'Ganho_Colunas_%'</span>]</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--- Impacto da Otimização Manual (Tempo em Segundos e Ganho %) ---"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>--- Impacto da Otimização Manual (Tempo em Segundos e Ganho %) ---</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabela_opt[cols].<span class="bu">round</span>(<span class="dv">2</span>).to_string(index<span class="op">=</span><span class="va">False</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Biblioteca  1_Leitura_Pura  2_Com_Tipagem  3_Apenas_Colunas  Ganho_Tipagem_%  Ganho_Colunas_%
     Julia           11.58            NaN               NaN              NaN              NaN
    Pandas            3.48           7.19              2.50          -106.91            28.06
    Polars            0.56           0.18              0.17            67.57            69.37
    R_Base           13.32           8.88             12.94            33.33             2.85
   R_Readr           12.43           8.49             12.54            31.70            -0.88</code></pre>
</div>
</div>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Biblioteca</strong></td>
<td><strong>Tempo Original (s)</strong></td>
<td><strong>Tempo c/ Tipos (s)</strong></td>
<td><strong>Impacto Tipagem</strong></td>
<td><strong>Tempo Só Colunas (s)</strong></td>
<td><strong>Impacto Seleção</strong></td>
</tr>
<tr class="even">
<td><strong>Polars</strong></td>
<td>0.56</td>
<td>0.18</td>
<td>▲ 67.6% (Melhora)</td>
<td>0.17</td>
<td>▲ 69.4% (Melhora)</td>
</tr>
<tr class="odd">
<td><strong>Pandas</strong></td>
<td>3.48</td>
<td>7.19</td>
<td>▼ -106.9% (Piora)</td>
<td>2.50</td>
<td>▲ 28.1% (Melhora)</td>
</tr>
<tr class="even">
<td><strong>R Base</strong></td>
<td>13.32</td>
<td>8.88</td>
<td>▲ 33.3% (Melhora)</td>
<td>12.94</td>
<td>▲ 2.9% (Marginal)</td>
</tr>
<tr class="odd">
<td><strong>R Readr</strong></td>
<td>12.43</td>
<td>8.49</td>
<td>▲ 31.7% (Melhora)</td>
<td>12.54</td>
<td>▼ -0.9% (Piora)</td>
</tr>
</tbody>
</table>
<p><strong>1. O Paradoxo da Tipagem Manual</strong> Definir os tipos de dados manualmente (<code>dtype={...}</code>) é uma prática comum para economizar memória, mas os testes mostram que ela pode <strong>prejudicar severamente</strong> a velocidade de leitura em certas bibliotecas.</p>
<ul>
<li><p><strong>A Armadilha do Pandas:</strong> Ao fornecer os tipos explicitamente, o tempo de leitura do Pandas <strong>piorou 106%</strong> (subindo de 3.48s para 7.19s). Isso ocorre porque a engine C do Pandas é altamente otimizada para inferência rápida. Ao forçar tipos, acionam-se validadores e conversores Python/Cython mais lentos, criando um gargalo de CPU desnecessário.</p></li>
<li><p><strong>A Necessidade do R:</strong> Diferente do Pandas, tanto o R Base quanto o <code>readr</code> dependem da tipagem manual para performance. Ao evitar a “adivinhação” de tipos linha a linha, o R obteve um ganho de performance de <strong>~30%</strong>.</p></li>
<li><p><strong>Polars Acelerado:</strong> O Polars, já sendo o mais rápido (0.56s), conseguiu reduzir seu tempo para 0.18s com tipagem, mostrando que sua engine sabe aproveitar metadados para alocar memória de forma mais eficiente.</p></li>
</ul>
<p><strong>2. Seleção de Colunas (Projection Pushdown)</strong> A estratégia de ler apenas as colunas necessárias demonstrou ser a otimização mais segura e eficaz para ferramentas modernas.</p>
<ul>
<li><p><strong>Polars (O Vencedor):</strong> Obteve uma melhoria de <strong>~69%</strong>, caindo para impressionantes <strong>0.17s</strong>. Isso confirma que o Polars implementa um verdadeiro <em>Projection Pushdown</em> no leitor de CSV, ignorando fisicamente o parsing de bytes das colunas não solicitadas.</p></li>
<li><p><strong>Pandas (Ganho Moderado):</strong> Obteve um ganho de <strong>28%</strong>. Embora útil, o ganho é menor que no Polars, indicando que o Pandas ainda realiza parte do processamento da linha inteira antes de descartar os dados.</p></li>
<li><p><strong>R (Ineficaz em CSV):</strong> A seleção de colunas teve impacto nulo ou negativo no R Base e <code>readr</code>. Isso sugere que, para arquivos de texto (CSV), essas bibliotecas leem a linha completa para a memória antes de filtrar as colunas, não economizando I/O ou CPU significativamente.</p></li>
</ul>
<blockquote class="blockquote">
<p><strong>Veredito Prático:</strong></p>
<ul>
<li><p>Em <strong>Pandas</strong>: <strong>Nunca</strong> defina tipos manualmente visando velocidade (apenas memória). Use sempre <code>usecols</code> para filtrar colunas.</p></li>
<li><p>Em <strong>Polars</strong>: Ambas as otimizações funcionam, mas a seleção de colunas é a “bala de prata”.</p></li>
<li><p>Em <strong>R</strong>: Se for obrigado a usar CSV, gaste tempo definindo o <code>colClasses</code> (tipos), pois é onde está o maior ganho.</p></li>
</ul>
</blockquote>
</section>
<section id="inteligência-de-leitura-o-efeito-projection-pushdown" class="level4">
<h4 class="anchored" data-anchor-id="inteligência-de-leitura-o-efeito-projection-pushdown">4.5. Inteligência de Leitura: O Efeito <em>Projection Pushdown</em></h4>
<p>Uma das otimizações mais críticas em Big Data é o <em>Column Pruning</em> (podar colunas): instruir a ferramenta a ler apenas as colunas necessárias para a análise, ignorando o resto.</p>
<p>A tabela abaixo mede a eficiência de cada biblioteca em aplicar essa técnica no dataset CSV <code>Yellow_Long</code>. O indicador “Ganho de Performance” revela se a biblioteca realmente ignorou os dados desnecessários (<em>Projection Pushdown</em>) ou se leu tudo para filtrar depois.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 24%">
<col style="width: 29%">
</colgroup>
<tbody>
<tr class="odd">
<td>Biblioteca</td>
<td>Leitura Total (s)</td>
<td>Leitura Parcial (s)</td>
<td>Ganho de Performance (%)</td>
</tr>
<tr class="even">
<td><strong>Polars</strong></td>
<td>0.56</td>
<td>0.17</td>
<td>▲ 69.4%</td>
</tr>
<tr class="odd">
<td><strong>Pandas</strong></td>
<td>3.48</td>
<td>2.50</td>
<td>▲ 28.1%</td>
</tr>
<tr class="even">
<td><strong>R Base</strong></td>
<td>13.32</td>
<td>12.94</td>
<td>▲ 2.9%</td>
</tr>
<tr class="odd">
<td><strong>R Readr</strong></td>
<td>12.43</td>
<td>12.54</td>
<td>▼ -0.9%</td>
</tr>
</tbody>
</table>
<p><strong>Análise Técnica</strong></p>
<ol type="1">
<li><p><strong>Polars e o <em>True Pushdown</em>:</strong> O Polars apresentou uma redução de tempo drástica (<strong>~70%</strong>). Isso comprova que sua engine de leitura é capaz de realizar <em>Projection Pushdown</em> físico em arquivos CSV. Ao identificar que apenas certas colunas são necessárias, o Polars pula o <em>parsing</em> (interpretação de texto para binário) das colunas ignoradas, economizando ciclos de CPU massivos. É uma leitura “inteligente”.</p></li>
<li><p><strong>Pandas e o <em>Post-Read Filter</em>:</strong> O Pandas obteve um ganho moderado (<strong>28%</strong>). Embora útil, o ganho não é proporcional à redução de dados. Isso indica que o Pandas ainda precisa escanear a estrutura da linha e realizar alocações parciais antes de descartar as colunas indesejadas. O ganho vem mais da economia de memória RAM do que de processamento bruto.</p></li>
<li><p><strong>R (Base e Readr): Leitura Cega:</strong> As ferramentas de R apresentaram ganho nulo ou marginal. Isso sugere que, para o formato CSV, essas bibliotecas realizam a leitura completa do arquivo para a memória (ou buffer) antes de selecionar as colunas. Ou seja, pedir 2 colunas ou 20 colunas leva o mesmo tempo de processamento; a economia ocorre apenas na memória final ocupada, não na velocidade de ingestão.</p></li>
</ol>
<blockquote class="blockquote">
<p><strong>Conclusão:</strong> Para pipelines de alta performance onde apenas um subconjunto dos dados é necessário, o <strong>Polars</strong> é a única ferramenta que transforma essa redução lógica em ganho de velocidade real. Em R e Pandas, selecionar colunas ajuda na memória, mas não resolve gargalos de tempo de leitura em CSV.</p>
</blockquote>
</section>
</section>
<section id="discussão-developer-experience-dx" class="level3">
<h3 class="anchored" data-anchor-id="discussão-developer-experience-dx">5. Discussão: Developer Experience (DX)</h3>
<p>Enquanto as seções anteriores focaram na eficiência computacional, esta discussão aborda a “Experiência do Desenvolvedor” (DX). A escolha de uma ferramenta não ocorre por nada: ela envolve um <em>trade-off</em> entre a velocidade de execução do código e a velocidade de escrita do mesmo.</p>
<p><strong>5.1. A Curva de Adoção do Polars</strong> A transição do Pandas para o Polars não se comporta como uma simples troca de sintaxe, mas assemelha-se à de fato estar aprendendo uma nova linguagem. O Polars embora muito bem estruturado e robusto,impõe uma barreira de entrada significativa para quem possui memória muscular desenvolvida no estilo imperativo do Pandas (Caso de quem escreveu isso aqui).</p>
<p>Durante os experimentos, observou-se que o rigor do Polars quanto à tipagem (definir o schema (tiposde colunas)) de dados atua como uma faca de dois gumes que pode ser um pouco chato no começo. Em datasets volumosos (Giga Yellow), a inferência de tipos estrita gerou exceções que impediram a leitura imediata, exigindo intervenções manuais de configuração antes mesmo do processamento iniciar. Em contrapartida, a permissividade do Pandas permitiu uma ingestão inicial mais fluida (“plug-and-play”), ainda que ao custo de performance posterior. Na nossa concepção do grupo, o polars de fato é uma linguagem muito mais robusta quando se está trabalhando em um ecossitema que exige um maior nível de profissionalidade e eficiência do código importa mais do que a facilidade de escrita e de utilização. Porém, (Fala do Diego) eu ainda continuo importanto o pandas toda vez que abro um arquivo em python novo, é muito mais prático para tarefas que não justificam o ganho de eficiência mostrada anteriormente.</p>
<p><strong>5.2. A Coesão do Ecossistema R</strong> Diferente da fragmentação que por vezes ocorre ao integrar bibliotecas de alta performance em outros ambientes, a utilização do <code>readr</code> e <code>arrow</code> no ecossistema R demonstrou consistência. A integração dessas ferramentas (backend C++, isso justifica a alta velocidade)com a sintaxe do R manteve-se transparente, não exigindo alterações drásticas no fluxo de trabalho habitual de um estatístico.</p>
<p><strong>5.3. Considerações sobre o Aprendizado</strong> A análise qualitativa sugere que a dificuldade associada ao Polars. A arquitetura da biblioteca força boas práticas de engenharia de dados desde a leitura. Conclui-se que, se o Polars fosse a primeira ferramenta apresentada a um estudante, a percepção de dificuldade seria mitigada, estabelecendo um padrão mental mais eficiente desde o início. O esforço de migração gera uma recompensa assimétrica: o custo cognitivo inicial é alto, mas o ganho de escalabilidade e a redução de dívida técnica no longo prazo são substanciais. No caso de R, não há nenhuma justificativa em utilizar a Base do R em contrapartida ao ReadR, ambos tem uma usabilidade muito parecida e o ganho de performance é muito grande entre ambas. Entre a seleção de R e Python, é uma coisa muito pessoal e depende muito da área de atuação do Cientista de Dados/Estatístico, porém, se a necessidade é o “Importador de bibliotecas mais rápido” sempre opte pelo Polars.<br>
</p>
<p><strong>5.4. O Declínio do CSV</strong> A persistência do CSV como padrão na indústria revela um conflito entre legibilidade humana e eficiência de máquina. Embora o CSV ofereça a vantagem da facilidade de uso, podendo ser aberto desde o Bloco de Notas até o Excel, ele transfere a vantagem da estruturação simples para o momento da leitura (que precisa decodificar todo o arquivo).</p>
<p>Sob a ótica da Experiência do Desenvolvedor (DX), o formato Parquet se mostrou não apenas superior em performance, mas também em robustez. Grande parte da fricção relatada com o Polars (a necessidade de configurar tipos manuais e tratar erros de inferência) desaparece ao utilizar Parquet. Diferente do CSV, que é “esquecido” de sua estrutura a cada salvamento, o Parquet preserva os metadados e o esquema (<em>schema</em>) do dataset. Isso significa que um arquivo salvo como <code>Int64</code> será lido como <code>Int64</code>, eliminando a adivinhação custosa e propensa a erros que as bibliotecas precisam realizar a cada leitura de texto.</p>
<p>A análise sugere uma mudança de paradigma no fluxo de trabalho: o CSV deve ser relegado estritamente às pontas do pipeline (recebimento de dados brutos de terceiros ou entrega final para relatórios ou para o cliente). Para todas as etapas intermediárias de armazenamento e processamento, o Parquet elimina ambiguidades técnicas, agindo como um contrato de dados estável entre diferentes sessões e ferramentas.</p>
<p>Utilize Parquet!</p>
<p><strong>5.5. O Júlia como uma outra alternativa</strong> O Julia se tornou uma ótima alternativa para quem se interessaem aprender mais sobre outra linguagem e ter o desempenho muito rápido. Com uma sintaxe não muito complexa se mostra uma alternativa interessante que resolver o problema que tanto o R quando o python tem.</p>
</section>
<section id="guia-prático-de-seleção-o-motivador-de-todo-trabalho" class="level3">
<h3 class="anchored" data-anchor-id="guia-prático-de-seleção-o-motivador-de-todo-trabalho">6. Guia Prático de Seleção (o motivador de todo trabalho)</h3>
</section>
<section id="a-regra-do-novo-padrão" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-do-novo-padrão">. A Regra do Novo Padrão</h3>
<blockquote class="blockquote">
<p><strong>“Vai começar agora? Comece com Polars.”</strong> Se o seu dado cabe na memória RAM, o Polars deve ser sua primeira escolha. Aprender a sintaxe dele é chato no começo? É. Mas ele é 4x mais rápido que o Pandas e te protege de erros bobos de tipagem. O investimento se paga rápido.</p>
</blockquote>
</section>
<section id="a-regra-do-legado" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-do-legado">2. A Regra do Legado</h3>
<blockquote class="blockquote">
<p><strong>“Não conserte o que não está lento.”</strong> Se você tem um script em Pandas que roda em 10 segundos, não perca 2 horas reescrevendo ele em Polars para ganhar 5 segundos. O Pandas ainda é ótimo para protótipos rápidos e datasets pequenos (abaixo de 500MB). Use o tempo para analisar dados, não para refatorar código.</p>
</blockquote>
</section>
<section id="a-regra-do-formato" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-do-formato">3. A Regra do Formato!</h3>
<blockquote class="blockquote">
<p><strong>“CSV é para transporte, Parquet é para trabalho.”</strong> A maior otimização que você pode fazer não é trocar de linguagem, é trocar de arquivo. Nossos testes mostraram ganhos de até <strong>28x</strong> (com Julia) só de sair do CSV para o Parquet. Use CSV só se o cliente exigir; internamente, salve tudo em Parquet.</p>
</blockquote>
</section>
<section id="a-regra-da-otimização" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-da-otimização">4. A Regra da Otimização</h3>
<blockquote class="blockquote">
<p><strong>“Selecione colunas sempre. Tipagem manual? Depende.”</strong> Se for obrigado a ler um CSV gigante:</p>
</blockquote>
<ul>
<li><p><strong>Sempre</strong> diga para a biblioteca quais colunas você quer (<code>select</code> ou <code>usecols</code>). Isso economiza muita memória.</p></li>
<li><p><strong>Cuidado no Pandas:</strong> Definir os tipos na mão (<code>int</code>, <code>float</code>) fez o Pandas ficar <strong>mais lento</strong> nos nossos testes. Deixe ele se virar sozinho.</p></li>
<li><p><strong>No Polars, R e Julia:</strong> Definir tipos na mão ajuda e deixa tudo mais rápido.</p></li>
</ul>
</section>
<section id="a-regra-do-usuário-de-r" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-do-usuário-de-r">5. A Regra do Usuário de R</h3>
<blockquote class="blockquote">
<p><strong>“Aposente o <code>read.csv</code>.”</strong> Se você usa R, esqueça que a função nativa <code>read.csv</code> existe. Ela é lenta demais. Use sempre os pacotes <code>readr</code> ou <code>arrow</code>. Com eles, o R fica tão competitivo quanto o Python.</p>
</blockquote>
</section>
<section id="a-regra-da-julia-o-desafiante" class="level3">
<h3 class="anchored" data-anchor-id="a-regra-da-julia-o-desafiante">6. A Regra da Julia (O Desafiante)</h3>
<blockquote class="blockquote">
<p><strong>“Julia é para quem tem pressa no fim, e paciência no começo.”</strong> A Julia foi a campeã absoluta na leitura de Parquet (8 segundos), batendo todo mundo. O preço? O tempo de “aquecimento” (compilação JIT) na primeira rodada. Se o seu pipeline é pesado e recorrente, migrar para Julia vai te dar a maior performance possível. Se for um script rápido de uma vez só, o tempo de compilação pode não valer a pena.</p>
</blockquote>
</section>
<section id="a-guerra-das-linguagens-python-vs.-r-vs.-julia" class="level3">
<h3 class="anchored" data-anchor-id="a-guerra-das-linguagens-python-vs.-r-vs.-julia">7. A Guerra das Linguagens (Python vs.&nbsp;R vs.&nbsp;Julia)</h3>
<blockquote class="blockquote">
<p><strong>“Não existe bala de prata, existe a ferramenta certa para o formato certo.”</strong> Nossos testes provaram que a “guerra” depende do terreno:</p>
</blockquote>
<ul>
<li><p><strong>No CSV (Força Bruta):</strong> O <strong>Python (com Polars)</strong> ganha de lavada. É a melhor ferramenta para mastigar texto sujo.</p></li>
<li><p><strong>No Parquet (Leitura Otimizada):</strong> A <strong>Julia</strong> assumiu a ponta, com o <strong>R (readr)</strong> e <strong>Polars</strong> logo atrás.</p></li>
<li><p><strong>Resumo:</strong> Se o dado já está em Parquet, a linguagem não importa tanto (todas são rápidas). Use a que você gosta mais. Se for CSV, vá de Polars.</p></li>
</ul>
</section>
<section id="conclusão-eficiência-como-sobrevivência-no-limite-do-hardware" class="level3">
<h3 class="anchored" data-anchor-id="conclusão-eficiência-como-sobrevivência-no-limite-do-hardware">7. Conclusão: Eficiência como Sobrevivência no Limite do Hardware</h3>
<p>Este estudo iniciou-se com uma pergunta sobre velocidade (<strong>“Quem é mais rápido?”</strong>), mas os dados revelaram uma questão mais crítica sobre viabilidade (<strong>“Quem consegue terminar a tarefa?”</strong>).</p>
<p>Ao submeter um notebook de alta performance (i7, 16GB RAM) a um dataset de escala Gigabyte, observamos o fenômeno do <strong>“Muro do Hardware”</strong>. Todas as bibliotecas testadas atingiram o teto físico de <strong>15.71 GB</strong> de memória RAM no teste de estresse. Nesse cenário limite, a eficiência da ferramenta deixa de ser uma questão de economizar segundos e passa a determinar se o workflow é executável ou se resultará em um erro fatal de <em>Out of Memory</em> (OOM).</p>
<section id="a-sobrevivência-local" class="level4">
<h4 class="anchored" data-anchor-id="a-sobrevivência-local">A Sobrevivência Local</h4>
<p>Para o Cientista de Dados que opera localmente, fora de clusters infinitos na nuvem, a conclusão é clara:</p>
<ol type="1">
<li><p><strong>Otimização é Obrigatória:</strong> O uso de formatos colunares (<strong>Parquet</strong>) e técnicas de leitura seletiva (<em>Projection Pushdown</em>) deixaram de ser apenas “boas práticas” para se tornarem requisitos funcionais. São os únicos mecanismos que permitem processar volumes de dados superiores à memória física disponível, mitigando o gargalo de <em>Swap</em> em disco.</p></li>
<li><p><strong>A Hegemonia das Novas Arquiteturas:</strong> O estudo comprovou a superioridade das ferramentas modernas sobre as legadas.</p>
<ul>
<li><p><strong>No caos do CSV:</strong> O <strong>Polars</strong> provou ser a ferramenta mais resiliente, gerenciando memória agressivamente para entregar performance mesmo sob saturação, algo que as engines <em>single-core</em> (Pandas e R Base) não conseguiram acompanhar.</p></li>
<li><p><strong>Na ordem do Parquet:</strong> A <strong>Julia</strong> demonstrou que, quando o dado está estruturado, sua arquitetura <em>Just-in-Time</em> é imbatível, liderando o ranking de velocidade pura.</p></li>
</ul></li>
</ol>
</section>
<section id="o-horizonte-de-escalabilidade" class="level4">
<h4 class="anchored" data-anchor-id="o-horizonte-de-escalabilidade">O Horizonte de Escalabilidade</h4>
<p>Embora ferramentas como Polars, Julia e <code>readr</code> estendam significativamente a vida útil do hardware local, permitindo análises de Big Data em um laptop, existe um limite físico intransponível.</p>
<p>Quando o volume de dados ultrapassa consistentemente a barreira da RAM (mesmo com todas as otimizações aplicadas) ou quando o tempo de processamento inviabiliza a iteração ágil, a solução deixa de ser “trocar a biblioteca” e passa a ser <strong>“trocar a infraestrutura”</strong>. Neste ponto, os conceitos validados aqui — preferência por Parquet, execução <em>Lazy</em> e Tipagem Estrita — tornam-se a base necessária para migrar para frameworks distribuídos (como Apache Spark ou Dask), onde a lógica de eficiência permanece a mesma, mas a escala torna-se horizontal.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>